{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty(1) :  tensor([0., 0., 0., 0., 0.])\n",
      "\n",
      "empty(2,3) tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "empty(2,2,3) tensor([[[8.6699e-22, 2.0963e-42, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n",
      "\n",
      "torch rand(5,3) :  tensor([[0.1938, 0.2477, 0.0695],\n",
      "        [0.8185, 0.9175, 0.3197],\n",
      "        [0.1956, 0.6754, 0.9968],\n",
      "        [0.5473, 0.3336, 0.3468],\n",
      "        [0.3303, 0.4387, 0.9463]])\n",
      "\n",
      "torch zeros(5,3) :  tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.empty(5)\n",
    "print(\"empty(1) : \",x)\n",
    "print()\n",
    "\n",
    "x = torch.empty(2,3)\n",
    "print(\"empty(2,3)\",x)\n",
    "print()\n",
    "\n",
    "x = torch.empty(2,2,3)\n",
    "print(\"empty(2,2,3)\",x)\n",
    "print()\n",
    "\n",
    "x = torch.rand(5,3)\n",
    "print(\"torch rand(5,3) : \",x)\n",
    "print()\n",
    "\n",
    "x = torch.zeros(5,3)\n",
    "print(\"torch zeros(5,3) : \",x)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "5 3\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x.shape[0],x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5000, 1.0000, 3.0000, 5.0000])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([4.5,1,3,5])\n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5000, 3.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([4.5,3],requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8388, 1.4363],\n",
      "        [1.2664, 1.9304],\n",
      "        [1.6593, 1.3199]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3,2)\n",
    "y = torch.rand(3,2)\n",
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8949, 0.4608, 0.7747],\n",
      "        [0.9170, 0.4717, 0.6957]])\n",
      "tensor([[1.8119, 0.9326, 1.4705],\n",
      "        [1.8119, 0.9326, 1.4705],\n",
      "        [1.8119, 0.9326, 1.4705]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3,2)\n",
    "y = torch.rand(2,3)\n",
    "print(y)\n",
    "print(torch.matmul(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0062, 0.6650, 0.8088, 0.1825, 0.0497, 0.8183, 0.7953, 0.5916, 0.6533,\n",
      "         0.1093],\n",
      "        [0.4089, 0.8551, 0.0242, 0.8195, 0.0752, 0.2572, 0.0583, 0.1369, 0.8128,\n",
      "         0.1411],\n",
      "        [0.7913, 0.7704, 0.8513, 0.2365, 0.9464, 0.3255, 0.4079, 0.3316, 0.1948,\n",
      "         0.8558],\n",
      "        [0.7497, 0.2354, 0.8459, 0.9567, 0.8703, 0.0608, 0.7966, 0.0688, 0.5712,\n",
      "         0.0195],\n",
      "        [0.4808, 0.4690, 0.5356, 0.9809, 0.5221, 0.5331, 0.9474, 0.9238, 0.7290,\n",
      "         0.7773],\n",
      "        [0.2060, 0.3447, 0.8929, 0.9192, 0.8168, 0.1305, 0.9160, 0.4788, 0.8838,\n",
      "         0.8304],\n",
      "        [0.7694, 0.5341, 0.7339, 0.1206, 0.3784, 0.2705, 0.1298, 0.0150, 0.0828,\n",
      "         0.8834],\n",
      "        [0.9410, 0.4650, 0.5860, 0.2860, 0.6720, 0.5975, 0.4636, 0.7977, 0.8763,\n",
      "         0.4206],\n",
      "        [0.2397, 0.4355, 0.9807, 0.4824, 0.1965, 0.6245, 0.2618, 0.5643, 0.8333,\n",
      "         0.4056],\n",
      "        [0.7910, 0.2736, 0.5202, 0.7087, 0.2597, 0.0498, 0.0514, 0.7481, 0.7883,\n",
      "         0.6721]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(10,10,device=device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "Matrix size: 10x10\n",
      "CPU time: 0.002996 seconds\n",
      "GPU time: 0.025887 seconds\n",
      "Speedup: 0.12x\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Check if CUDA is available\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"CUDA is not available. Please make sure your PyTorch installation has CUDA support.\")\n",
    "else:\n",
    "    print(\"CUDA is available!\")\n",
    "\n",
    "# Define a function to benchmark matrix multiplication on CPU and GPU\n",
    "def benchmark_matrix_multiplication(size):\n",
    "    # Create random matrices\n",
    "    A = torch.randn(size, size)\n",
    "    B = torch.randn(size, size)\n",
    "\n",
    "    # Perform matrix multiplication on CPU\n",
    "    start_time = time.time()\n",
    "    C_cpu = torch.matmul(A, B)\n",
    "    cpu_time = time.time() - start_time\n",
    "\n",
    "    # Move matrices to GPU\n",
    "    A_gpu = A.to('cuda')\n",
    "    B_gpu = B.to('cuda')\n",
    "\n",
    "    # Perform matrix multiplication on GPU\n",
    "    torch.cuda.synchronize()  # Ensure all GPU operations are complete\n",
    "    start_time = time.time()\n",
    "    C_gpu = torch.matmul(A_gpu, B_gpu)\n",
    "    torch.cuda.synchronize()  # Ensure all GPU operations are complete\n",
    "    gpu_time = time.time() - start_time\n",
    "\n",
    "    return cpu_time, gpu_time\n",
    "\n",
    "# Set matrix size for benchmarking\n",
    "matrix_size = 10  # You can adjust this size to your needs\n",
    "\n",
    "# Run the benchmark\n",
    "cpu_time, gpu_time = benchmark_matrix_multiplication(matrix_size)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Matrix size: {matrix_size}x{matrix_size}\")\n",
    "print(f\"CPU time: {cpu_time:.6f} seconds\")\n",
    "print(f\"GPU time: {gpu_time:.6f} seconds\")\n",
    "print(f\"Speedup: {cpu_time / gpu_time:.2f}x\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10., requires_grad=True)\n",
      "\n",
      "tensor(100., grad_fn=<PowBackward0>)\n",
      "\n",
      "tensor(20.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Gradient\n",
    "# Define a tensor with gradient tracking enabled\n",
    "x = torch.tensor(10.0, requires_grad=True)\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "# perform operations on the tensor y=x^2\n",
    "y = x**2\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "# calculate the gradient of y with respect to x [ dy/dx = d(x^2)/dx = 2x ] \n",
    "y.backward()\n",
    "print(x.grad)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression Autograd\n",
    "x = torch.tensor([1,2,3,4,5,6,7])\n",
    "y = torch.tensor([2,4,6,8,10,12,14])\n",
    "weight = torch.tensor(4.0,requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return x*weight\n",
    "\n",
    "def loss_function(y_pred,y):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "x_test = 6\n",
    "forward(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : 3.1999998092651367, loss : 80.0\n",
      "weight : 2.7199997901916504, loss : 28.79998779296875\n",
      "weight : 2.431999921798706, loss : 10.367995262145996\n",
      "weight : 2.259199857711792, loss : 3.7324790954589844\n",
      "weight : 2.155519962310791, loss : 1.3436909914016724\n",
      "weight : 2.0933120250701904, loss : 0.48372918367385864\n",
      "weight : 2.0559871196746826, loss : 0.17414256930351257\n",
      "weight : 2.0335922241210938, loss : 0.0626910850405693\n",
      "weight : 2.020155429840088, loss : 0.022568749263882637\n",
      "weight : 2.0120933055877686, loss : 0.008124832063913345\n",
      "weight : 2.007256031036377, loss : 0.0029249468352645636\n",
      "weight : 2.0043535232543945, loss : 0.0010530018480494618\n",
      "weight : 2.0026121139526367, loss : 0.0003790633345488459\n",
      "weight : 2.0015673637390137, loss : 0.00013646279694512486\n",
      "weight : 2.0009403228759766, loss : 4.913215525448322e-05\n",
      "weight : 2.0005640983581543, loss : 1.7684142221696675e-05\n",
      "weight : 2.000338554382324, loss : 6.363985448842868e-06\n",
      "weight : 2.0002031326293945, loss : 2.2923813958186656e-06\n",
      "weight : 2.000121831893921, loss : 8.252573024947196e-07\n",
      "weight : 2.000073194503784, loss : 2.9671917900486733e-07\n",
      "weight : 2.0000438690185547, loss : 1.0706400388471593e-07\n",
      "weight : 2.000026226043701, loss : 3.848981577903032e-08\n",
      "weight : 2.0000157356262207, loss : 1.374902591777527e-08\n",
      "weight : 2.000009536743164, loss : 4.956551169499335e-09\n",
      "weight : 2.0000057220458984, loss : 1.8189894035458565e-09\n",
      "weight : 2.0000033378601074, loss : 6.548361852765083e-10\n",
      "weight : 2.000001907348633, loss : 2.2198166915732287e-10\n",
      "weight : 2.0000011920928955, loss : 7.275957614183426e-11\n",
      "weight : 2.0000007152557373, loss : 2.98590353831063e-11\n",
      "weight : 2.000000476837158, loss : 9.46036912002901e-12\n",
      "weight : 2.000000238418579, loss : 4.7423653545819455e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n",
      "weight : 2.000000238418579, loss : 1.4698084329495265e-12\n"
     ]
    }
   ],
   "source": [
    "# Linear regression Autograd\n",
    "x = torch.tensor([1,2,3,4,5,6,7],dtype=torch.float32)\n",
    "y = torch.tensor([2,4,6,8,10,12,14],dtype=torch.float32)\n",
    "weight = torch.tensor(4.0,requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return x*weight\n",
    "\n",
    "def loss_function(y_pred,y):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "x_test = 6\n",
    "forward(torch.tensor(6))\n",
    "\n",
    "lr = 0.01\n",
    "for epoch in range(50):\n",
    "    \n",
    "    y_pred = forward(x)\n",
    "    loss = loss_function(y_pred,y)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        weight.data = weight.data - lr * weight.grad\n",
    "    weight.grad.zero_()\n",
    "    print(f\"weight : {weight.item()}, loss : {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.0000, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]],dtype=torch.float32)\n",
    "y = torch.tensor([[2],[4],[6],[8],[10],[12],[14],[16],[18],[20]],dtype=torch.float32)\n",
    "\n",
    "n_samples,n_features = x.shape\n",
    "print(n_samples,n_features)\n",
    "\n",
    "x_test = torch.tensor([45],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(LinearRegression,self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim,output_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape ,output_shape = n_features,n_features\n",
    "model = LinearRegression(n_features,n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([37.1818], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction before the training\n",
    "model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10, loss : 0.0822\n",
      "epoch : 20, loss : 0.0585\n",
      "epoch : 30, loss : 0.0398\n",
      "epoch : 40, loss : 0.0259\n",
      "epoch : 50, loss : 0.0160\n",
      "epoch : 60, loss : 0.0093\n",
      "epoch : 70, loss : 0.0051\n",
      "epoch : 80, loss : 0.0027\n",
      "epoch : 90, loss : 0.0013\n",
      "epoch : 100, loss : 0.0006\n",
      "epoch : 110, loss : 0.0002\n",
      "epoch : 120, loss : 0.0001\n",
      "epoch : 130, loss : 0.0000\n",
      "epoch : 140, loss : 0.0000\n",
      "epoch : 150, loss : 0.0000\n",
      "epoch : 160, loss : 0.0000\n",
      "epoch : 170, loss : 0.0000\n",
      "epoch : 180, loss : 0.0000\n",
      "epoch : 190, loss : 0.0000\n",
      "epoch : 200, loss : 0.0000\n",
      "epoch : 210, loss : 0.0000\n",
      "epoch : 220, loss : 0.0000\n",
      "epoch : 230, loss : 0.0000\n",
      "epoch : 240, loss : 0.0000\n",
      "epoch : 250, loss : 0.0000\n",
      "epoch : 260, loss : 0.0000\n",
      "epoch : 270, loss : 0.0000\n",
      "epoch : 280, loss : 0.0000\n",
      "epoch : 290, loss : 0.0000\n",
      "epoch : 300, loss : 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([90.], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ler = 0.01\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=ler)\n",
    "for epoch in range(300):\n",
    "    model.train()\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred,y)\n",
    "    \n",
    "    loss.backward() \n",
    "    \n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    #zero the grad after updating\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1)%10 == 0:\n",
    "        print(f\"epoch : {epoch+1}, loss : {loss.item():.4f}\")\n",
    "    \n",
    "    # prediction after the training\n",
    "model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
